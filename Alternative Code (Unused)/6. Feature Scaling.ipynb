{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e21e51-2b08-4405-8774-8c2d9ac5faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd064892-3a25-4f6b-916c-ecdd7df0075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 - import all libraries for data handling, feature extraction, clustering and plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9608fb6d-79e6-4087-9247-79f8918d081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce11bcd6-960a-4d21-931f-dad6b9bd110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2 - define function to load tweets data from the Dataset folder\n",
    "def load_tweets_data():\n",
    "    #use relative path\n",
    "    tweets_data = pd.read_csv(\"../Dataset/tweets.csv\")\n",
    "    return tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e65fbc4e-1ecd-4979-9d6c-dabef29adcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3 - define function to load NRC emotion lexicon from the Lexicon folder\n",
    "def load_nrc_lexicon():\n",
    "    #use relative path\n",
    "    lexicon_path = \"../Lexicon/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\"\n",
    "    lexicon = {}\n",
    "    with open(lexicon_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 3:\n",
    "                word, emotion, value = parts\n",
    "                if word not in lexicon:\n",
    "                    lexicon[word] = {}\n",
    "                lexicon[word][emotion] = int(value)\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae4665ac-c53f-4dc7-ac79-6828c4670368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                               link  \\\n",
      "0   0  https://twitter.com/HackneyPSC/status/17274436...   \n",
      "1   1  https://twitter.com/cherrysattitude/status/172...   \n",
      "2   2  https://twitter.com/diamoundgirls2/status/1710...   \n",
      "3   3  https://twitter.com/mmtchi/status/172764634165...   \n",
      "4   4  https://twitter.com/NoahIeeNG/status/172744319...   \n",
      "\n",
      "                                                text              date  likes  \\\n",
      "0  A statement from psychoanalytic activists:  Th...  11/22/2023 21:47      0   \n",
      "1                        bak bak bak bak doyamadƒ±nƒ±z  11/22/2023 15:27    443   \n",
      "2  Check out üèí 35 + different ERIK KARLSSON cards...    10/7/2023 7:15      0   \n",
      "3  Il s'en passe des trucs pendant qu'on vous ori...  11/23/2023 11:12    381   \n",
      "4  AW OKAY.. WELL THATS COOL, IM SURE PAL WILL AP...  11/22/2023 21:45      0   \n",
      "\n",
      "   comments  \n",
      "0         0  \n",
      "1         9  \n",
      "2         0  \n",
      "3        44  \n",
      "4         0  \n",
      "[('aback', {'anger': 0, 'anticipation': 0, 'disgust': 0, 'fear': 0, 'joy': 0, 'negative': 0, 'positive': 0, 'sadness': 0, 'surprise': 0, 'trust': 0}), ('abacus', {'anger': 0, 'anticipation': 0, 'disgust': 0, 'fear': 0, 'joy': 0, 'negative': 0, 'positive': 0, 'sadness': 0, 'surprise': 0, 'trust': 1}), ('abandon', {'anger': 0, 'anticipation': 0, 'disgust': 0, 'fear': 1, 'joy': 0, 'negative': 1, 'positive': 0, 'sadness': 1, 'surprise': 0, 'trust': 0}), ('abandoned', {'anger': 1, 'anticipation': 0, 'disgust': 0, 'fear': 1, 'joy': 0, 'negative': 1, 'positive': 0, 'sadness': 1, 'surprise': 0, 'trust': 0}), ('abandonment', {'anger': 1, 'anticipation': 0, 'disgust': 0, 'fear': 1, 'joy': 0, 'negative': 1, 'positive': 0, 'sadness': 1, 'surprise': 1, 'trust': 0})]\n"
     ]
    }
   ],
   "source": [
    "#testing of 2. Data Loading Functions\n",
    "tweets = load_tweets_data()\n",
    "lexicon = load_nrc_lexicon()\n",
    "print(tweets.head())\n",
    "print(list(lexicon.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "004b144c-10f2-4108-9af1-09c27f8f07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcef12cc-b0d1-4c2a-ae8f-7a91be1e60f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 - define function to preprocess the tweets data\n",
    "def preprocess_tweets_data(tweets_data):\n",
    "    #remove rows with missing tweets\n",
    "    tweets_data = tweets_data.dropna(subset=[\"text\"]).copy()\n",
    "    #convert text to lowercase for consistency\n",
    "    tweets_data[\"text\"] = tweets_data[\"text\"].str.lower()\n",
    "    #remove links\n",
    "    tweets_data[\"text\"] = tweets_data[\"text\"].apply(lambda x: re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", x))\n",
    "    return tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5c26fd7-02a6-49fa-819a-4c93f7b82892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                               link  \\\n",
      "0   0  https://twitter.com/HackneyPSC/status/17274436...   \n",
      "1   1  https://twitter.com/cherrysattitude/status/172...   \n",
      "2   2  https://twitter.com/diamoundgirls2/status/1710...   \n",
      "3   3  https://twitter.com/mmtchi/status/172764634165...   \n",
      "4   4  https://twitter.com/NoahIeeNG/status/172744319...   \n",
      "\n",
      "                                                text              date  likes  \\\n",
      "0  a statement from psychoanalytic activists:  th...  11/22/2023 21:47      0   \n",
      "1                        bak bak bak bak doyamadƒ±nƒ±z  11/22/2023 15:27    443   \n",
      "2  check out üèí 35 + different erik karlsson cards...    10/7/2023 7:15      0   \n",
      "3  il s'en passe des trucs pendant qu'on vous ori...  11/23/2023 11:12    381   \n",
      "4  aw okay.. well thats cool, im sure pal will ap...  11/22/2023 21:45      0   \n",
      "\n",
      "   comments  \n",
      "0         0  \n",
      "1         9  \n",
      "2         0  \n",
      "3        44  \n",
      "4         0  \n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "tweets = load_tweets_data()\n",
    "tweets = preprocess_tweets_data(tweets)\n",
    "print(tweets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9f4e079-c596-4760-9810-2670190bb509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2dae610-3676-49c7-83ce-610ba5e092f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 - extract username from twitter link\n",
    "def extract_username(link):\n",
    "    match = re.search(r\"twitter\\.com/([^/]+)/status\", str(link))\n",
    "    if match: \n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "#step 2 - a function to count emoji in text\n",
    "def count_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "    r\"[\\U0001F600-\\U0001F64F\"\n",
    "    r\"\\U0001F300-\\U0001F5FF\"\n",
    "    r\"\\U0001F680-\\U0001F6FF\"\n",
    "    r\"\\U0001F1E0-\\U0001F1FF]+\", flags=re.UNICODE)\n",
    "    return len(emoji_pattern.findall(str(text)))\n",
    "\n",
    "#step 3 - function to count hashtags\n",
    "def count_hashtags(text):\n",
    "    return len(re.findall(r\"#\\w+\", str(text)))\n",
    "\n",
    "#step 4 - function to get tweet length (num of characters)\n",
    "def get_tweet_length(text):\n",
    "    return len(str(text))\n",
    "\n",
    "#step 5 - function to count emotional words using NRC lexicon\n",
    "def count_emotion_words(text, lexicon, emotion):\n",
    "    words = str(text).split()\n",
    "    count = 0 \n",
    "    for word in words:\n",
    "        if word in lexicon and lexicon[word].get(emotion, 0) == 1:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "#step 6 - main function to extract all features for each tweet\n",
    "def extract_features(tweets_data, lexicon):\n",
    "    #extract username from link\n",
    "    tweets_data[\"username\"] = tweets_data[\"link\"].apply(extract_username)\n",
    "    #create feature columns for emoji, hashtags, tweet length, likes and comments\n",
    "    tweets_data[\"emoji_count\"] = tweets_data[\"text\"].apply(count_emojis)\n",
    "    tweets_data[\"hashtag_count\"] = tweets_data[\"text\"].apply(count_hashtags) \n",
    "    tweets_data[\"tweet_length\"] = tweets_data[\"text\"].apply(get_tweet_length)\n",
    "    #convert like and comment columns to numeric\n",
    "    tweets_data[\"likes\"] = pd.to_numeric(tweets_data[\"likes\"], errors=\"coerce\").fillna(0)\n",
    "    tweets_data[\"comments\"] = pd.to_numeric(tweets_data[\"comments\"], errors=\"coerce\")\n",
    "    #add NRC emotion features one column per emotion\n",
    "    emotions = [\"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"trust\", \"positive\", \"negative\"]\n",
    "    for emotion in emotions:\n",
    "        tweets_data[f\"emotion_{emotion}_count\"] = tweets_data[\"text\"].apply(lambda x: count_emotion_words(x, lexicon, emotion))\n",
    "    return tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d6bb27a-e3d3-49a5-bba0-91936a3c5547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          username                                               text  \\\n",
      "0       HackneyPSC  a statement from psychoanalytic activists:  th...   \n",
      "1  cherrysattitude                        bak bak bak bak doyamadƒ±nƒ±z   \n",
      "2   diamoundgirls2  check out üèí 35 + different erik karlsson cards...   \n",
      "3           mmtchi  il s'en passe des trucs pendant qu'on vous ori...   \n",
      "4        NoahIeeNG  aw okay.. well thats cool, im sure pal will ap...   \n",
      "\n",
      "   emoji_count  hashtag_count  likes  comments  \n",
      "0            0              0      0         0  \n",
      "1            0              0    443         9  \n",
      "2            1              4      0         0  \n",
      "3            0              1    381        44  \n",
      "4            0              0      0         0  \n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "tweets = extract_features(tweets, lexicon)\n",
    "print(tweets[[\"username\", \"text\", \"emoji_count\", \"hashtag_count\", \"likes\", \"comments\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96715c0a-f4c2-4da0-935b-3727aa4fbd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Aggregation to User level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d2f4b3a-5fe2-42d2-9ddf-d07dcfcc40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 - define function to aggregate tweet-level features to user-level\n",
    "def aggregate_to_user_level(tweets_data):\n",
    "    #group by username and calculate mean of numeric features for each user\n",
    "    user_features = tweets_data.groupby(\"username\").agg({\n",
    "        \"emoji_count\": \"mean\",\n",
    "        \"hashtag_count\": \"mean\",\n",
    "        \"tweet_length\": \"mean\",\n",
    "        \"likes\": \"mean\",\n",
    "        \"comments\": \"mean\",\n",
    "        \"emotion_anger_count\": \"mean\",\n",
    "        \"emotion_anticipation_count\": \"mean\",\n",
    "        \"emotion_disgust_count\": \"mean\",\n",
    "        \"emotion_fear_count\": \"mean\",\n",
    "        \"emotion_joy_count\": \"mean\",\n",
    "        \"emotion_sadness_count\": \"mean\",\n",
    "        \"emotion_surprise_count\": \"mean\",\n",
    "        \"emotion_trust_count\": \"mean\",\n",
    "        \"emotion_positive_count\": \"mean\",\n",
    "        \"emotion_negative_count\": \"mean\",\n",
    "    }).reset_index()\n",
    "    return user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fc3083a-831c-4d4f-8ba4-192a7510f9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      username  emoji_count  hashtag_count  tweet_length  likes  comments  \\\n",
      "0    001Flight          0.0            0.0          63.0    0.0       0.0   \n",
      "1    0130Coach          0.0            0.0         453.0    0.0       0.0   \n",
      "2       01IOTA          0.0            0.0         280.0   50.0       9.0   \n",
      "3  021Scenario          0.0            0.0          40.0    0.0       0.0   \n",
      "4        06Kiu          0.0            0.0          73.0  478.0      13.0   \n",
      "\n",
      "   emotion_anger_count  emotion_anticipation_count  emotion_disgust_count  \\\n",
      "0                  0.0                         0.0                    0.0   \n",
      "1                  1.0                         0.0                    0.0   \n",
      "2                  2.0                         1.0                    1.0   \n",
      "3                  0.0                         0.0                    0.0   \n",
      "4                  0.0                         0.0                    0.0   \n",
      "\n",
      "   emotion_fear_count  emotion_joy_count  emotion_sadness_count  \\\n",
      "0                 1.0                0.0                    0.0   \n",
      "1                 5.0                0.0                    2.0   \n",
      "2                 2.0                0.0                    1.0   \n",
      "3                 0.0                0.0                    0.0   \n",
      "4                 0.0                0.0                    0.0   \n",
      "\n",
      "   emotion_surprise_count  emotion_trust_count  emotion_positive_count  \\\n",
      "0                     0.0                  0.0                     0.0   \n",
      "1                     0.0                  5.0                     2.0   \n",
      "2                     1.0                  0.0                     1.0   \n",
      "3                     0.0                  0.0                     0.0   \n",
      "4                     0.0                  0.0                     0.0   \n",
      "\n",
      "   emotion_negative_count  \n",
      "0                     0.0  \n",
      "1                     5.0  \n",
      "2                     2.0  \n",
      "3                     0.0  \n",
      "4                     0.0  \n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "user_features = aggregate_to_user_level(tweets)\n",
    "print(user_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd8e4945-ad32-47d6-a6a0-dbdb4bc532d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "755258ea-40f7-4e47-993f-6e2a349b355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 - define function to scale user features using Standard Scaler\n",
    "def scale_features(user_features):\n",
    "    #select only numeric columns for scaling - skip \"username\"\n",
    "    feature_columns = user_features.columns.drop(\"username\")\n",
    "    scaler = StandardScaler()\n",
    "    scaled_values = scaler.fit_transform(user_features[feature_columns])\n",
    "    #create a new DataFrame with the scaled values + skipped \"username\"\n",
    "    scaled_df = pd.DataFrame(scaled_values, columns=feature_columns)\n",
    "    scaled_df[\"username\"] = user_features[\"username\"].values\n",
    "    #return the scaled Dataframe\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a251a915-cafb-447d-ba2f-ffc36c12b480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emoji_count  hashtag_count  tweet_length     likes  comments  \\\n",
      "0    -0.216797      -0.275886     -0.398846 -0.115727 -0.086424   \n",
      "1    -0.216797      -0.275886      0.913631 -0.115727 -0.086424   \n",
      "2    -0.216797      -0.275886      0.331430 -0.109018 -0.061325   \n",
      "3    -0.216797      -0.275886     -0.476248 -0.115727 -0.086424   \n",
      "4    -0.216797      -0.275886     -0.365192 -0.051590 -0.050170   \n",
      "\n",
      "   emotion_anger_count  emotion_anticipation_count  emotion_disgust_count  \\\n",
      "0            -0.449069                   -0.323141              -0.391037   \n",
      "1             0.412821                   -0.323141              -0.391037   \n",
      "2             1.274711                    0.615390               0.990815   \n",
      "3            -0.449069                   -0.323141              -0.391037   \n",
      "4            -0.449069                   -0.323141              -0.391037   \n",
      "\n",
      "   emotion_fear_count  emotion_joy_count  emotion_sadness_count  \\\n",
      "0            0.232071          -0.316548              -0.442799   \n",
      "1            2.974019          -0.316548               1.485252   \n",
      "2            0.917558          -0.316548               0.521226   \n",
      "3           -0.453416          -0.316548              -0.442799   \n",
      "4           -0.453416          -0.316548              -0.442799   \n",
      "\n",
      "   emotion_surprise_count  emotion_trust_count  emotion_positive_count  \\\n",
      "0               -0.365595            -0.328841               -0.334295   \n",
      "1               -0.365595             2.768026                0.501445   \n",
      "2                1.245150            -0.328841                0.083575   \n",
      "3               -0.365595            -0.328841               -0.334295   \n",
      "4               -0.365595            -0.328841               -0.334295   \n",
      "\n",
      "   emotion_negative_count     username  \n",
      "0               -0.482916    001Flight  \n",
      "1                2.102403    0130Coach  \n",
      "2                0.551211       01IOTA  \n",
      "3               -0.482916  021Scenario  \n",
      "4               -0.482916        06Kiu  \n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "scaled_df = scale_features(user_features)\n",
    "print(scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1309e8-7719-42ce-b6c1-2a396d2c3425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
