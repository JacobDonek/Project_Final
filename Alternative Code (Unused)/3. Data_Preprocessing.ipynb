{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e21e51-2b08-4405-8774-8c2d9ac5faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd064892-3a25-4f6b-916c-ecdd7df0075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 - import all libraries for data handling, feature extraction, clustering and plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9608fb6d-79e6-4087-9247-79f8918d081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce11bcd6-960a-4d21-931f-dad6b9bd110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2 - define function to load tweets data from the Dataset folder\n",
    "def load_tweets_data():\n",
    "    #use relative path\n",
    "    tweets_data = pd.read_csv(\"../Dataset/tweets.csv\")\n",
    "    return tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e65fbc4e-1ecd-4979-9d6c-dabef29adcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3 - define function to load NRC emotion lexicon from the Lexicon folder\n",
    "def load_nrc_lexicon():\n",
    "    #use relative path\n",
    "    lexicon_path = \"../Lexicon/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\"\n",
    "    lexicon = {}\n",
    "    with open(lexicon_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 3:\n",
    "                word, emotion, value = parts\n",
    "                if word not in lexicon:\n",
    "                    lexicon[word] = {}\n",
    "                lexicon[word][emotion] = int(value)\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae4665ac-c53f-4dc7-ac79-6828c4670368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                               link  \\\n",
      "0   0  https://twitter.com/HackneyPSC/status/17274436...   \n",
      "1   1  https://twitter.com/cherrysattitude/status/172...   \n",
      "2   2  https://twitter.com/diamoundgirls2/status/1710...   \n",
      "3   3  https://twitter.com/mmtchi/status/172764634165...   \n",
      "4   4  https://twitter.com/NoahIeeNG/status/172744319...   \n",
      "\n",
      "                                                text              date  likes  \\\n",
      "0  A statement from psychoanalytic activists:  Th...  11/22/2023 21:47      0   \n",
      "1                        bak bak bak bak doyamadƒ±nƒ±z  11/22/2023 15:27    443   \n",
      "2  Check out üèí 35 + different ERIK KARLSSON cards...    10/7/2023 7:15      0   \n",
      "3  Il s'en passe des trucs pendant qu'on vous ori...  11/23/2023 11:12    381   \n",
      "4  AW OKAY.. WELL THATS COOL, IM SURE PAL WILL AP...  11/22/2023 21:45      0   \n",
      "\n",
      "   comments  \n",
      "0         0  \n",
      "1         9  \n",
      "2         0  \n",
      "3        44  \n",
      "4         0  \n",
      "[('aback', {'anger': 0, 'anticipation': 0, 'disgust': 0, 'fear': 0, 'joy': 0, 'negative': 0, 'positive': 0, 'sadness': 0, 'surprise': 0, 'trust': 0}), ('abacus', {'anger': 0, 'anticipation': 0, 'disgust': 0, 'fear': 0, 'joy': 0, 'negative': 0, 'positive': 0, 'sadness': 0, 'surprise': 0, 'trust': 1}), ('abandon', {'anger': 0, 'anticipation': 0, 'disgust': 0, 'fear': 1, 'joy': 0, 'negative': 1, 'positive': 0, 'sadness': 1, 'surprise': 0, 'trust': 0}), ('abandoned', {'anger': 1, 'anticipation': 0, 'disgust': 0, 'fear': 1, 'joy': 0, 'negative': 1, 'positive': 0, 'sadness': 1, 'surprise': 0, 'trust': 0}), ('abandonment', {'anger': 1, 'anticipation': 0, 'disgust': 0, 'fear': 1, 'joy': 0, 'negative': 1, 'positive': 0, 'sadness': 1, 'surprise': 1, 'trust': 0})]\n"
     ]
    }
   ],
   "source": [
    "#testing of 2. Data Loading Functions\n",
    "tweets = load_tweets_data()\n",
    "lexicon = load_nrc_lexicon()\n",
    "print(tweets.head())\n",
    "print(list(lexicon.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "004b144c-10f2-4108-9af1-09c27f8f07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcef12cc-b0d1-4c2a-ae8f-7a91be1e60f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 - define function to preprocess the tweets data\n",
    "def preprocess_tweets_data(tweets_data):\n",
    "    #remove rows with missing tweets\n",
    "    tweets_data = tweets_data.dropna(subset=[\"text\"]).copy()\n",
    "    #convert text to lowercase for consistency\n",
    "    tweets_data[\"text\"] = tweets_data[\"text\"].str.lower()\n",
    "    #remove links\n",
    "    tweets_data[\"text\"] = tweets_data[\"text\"].apply(lambda x: re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", x))\n",
    "    return tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5c26fd7-02a6-49fa-819a-4c93f7b82892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                               link  \\\n",
      "0   0  https://twitter.com/HackneyPSC/status/17274436...   \n",
      "1   1  https://twitter.com/cherrysattitude/status/172...   \n",
      "2   2  https://twitter.com/diamoundgirls2/status/1710...   \n",
      "3   3  https://twitter.com/mmtchi/status/172764634165...   \n",
      "4   4  https://twitter.com/NoahIeeNG/status/172744319...   \n",
      "\n",
      "                                                text              date  likes  \\\n",
      "0  a statement from psychoanalytic activists:  th...  11/22/2023 21:47      0   \n",
      "1                        bak bak bak bak doyamadƒ±nƒ±z  11/22/2023 15:27    443   \n",
      "2  check out üèí 35 + different erik karlsson cards...    10/7/2023 7:15      0   \n",
      "3  il s'en passe des trucs pendant qu'on vous ori...  11/23/2023 11:12    381   \n",
      "4  aw okay.. well thats cool, im sure pal will ap...  11/22/2023 21:45      0   \n",
      "\n",
      "   comments  \n",
      "0         0  \n",
      "1         9  \n",
      "2         0  \n",
      "3        44  \n",
      "4         0  \n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "tweets = load_tweets_data()\n",
    "tweets = preprocess_tweets_data(tweets)\n",
    "print(tweets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f4e079-c596-4760-9810-2670190bb509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Feature Extraction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
